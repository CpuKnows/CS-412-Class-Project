{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import tensorflow as tf\n",
    "import os\n",
    "import csv\n",
    "\n",
    "#Import module from folder in another directory\n",
    "import importlib.util\n",
    "spec = importlib.util.spec_from_file_location(\"outliers\", \"data_preprocessing/outliers.py\")\n",
    "outliers = importlib.util.module_from_spec(spec)\n",
    "spec.loader.exec_module(outliers)\n",
    "\n",
    "import sys\n",
    "sys.path.append('data_preprocessing')\n",
    "import data_preprocessing.summary as summary\n",
    "import data_preprocessing.normalize as normalize\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "from sklearn.cross_validation import train_test_split\n",
    "from sklearn.model_selection import KFold, GridSearchCV\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.metrics import r2_score\n",
    "from sklearn import svm\n",
    "\n",
    "#import xgboost as xgb\n",
    "\n",
    "%matplotlib inline\n",
    "\n",
    "rng = np.random.RandomState(31337)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train_data = pd.read_csv('../data/input/ames_train.csv')\n",
    "test_data = pd.read_csv('../data/input/ames_test.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"train_data.set_index('Id', inplace=True)\\ntrain_data.drop(['PID', 'Latitude', 'Longitude'], axis=1, inplace=True)\\n\\ntest_data.set_index('Id', inplace=True)\\ntest_data.drop(['PID', 'Latitude', 'Longitude'], axis=1, inplace=True)\""
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''train_data.set_index('Id', inplace=True)\n",
    "train_data.drop(['PID', 'Latitude', 'Longitude'], axis=1, inplace=True)\n",
    "\n",
    "test_data.set_index('Id', inplace=True)\n",
    "test_data.drop(['PID', 'Latitude', 'Longitude'], axis=1, inplace=True)'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train_data = normalize.fill_in_missing_values(train_data)\n",
    "train_data = outliers.remove_outliers(train_data)\n",
    "#train_data = normalize.normalize(train_data)\n",
    "\n",
    "test_data = normalize.fill_in_missing_values(test_data)\n",
    "test_data = outliers.remove_outliers(test_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1844, 37)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data = train_data.select_dtypes(include=[np.number])\n",
    "test_data = test_data.select_dtypes(include=[np.number])\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(train_data.loc[:, train_data.columns != 'SalePrice'], \n",
    "                                                  train_data['SalePrice'],\n",
    "                                                  test_size=0.2, random_state=42)\n",
    "X_train = X_train.values\n",
    "X_test = X_test.values\n",
    "y_train = y_train.values\n",
    "y_test = y_test.values\n",
    "\n",
    "X_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initialized\n",
      "Cost at step 0: 52207416.15\n"
     ]
    }
   ],
   "source": [
    "\n",
    "train_size = np.shape(X_train)[0]\n",
    "test_size = np.shape(X_test)[0]\n",
    "num_features = np.shape(X_train)[1]\n",
    "num_hidden = 16 # Number of activation units in the hidden layer\n",
    "\n",
    "\n",
    "# Neural network with one hidden layer\n",
    "graph = tf.Graph()\n",
    "with graph.as_default():\n",
    "\n",
    "    # Input\n",
    "    tf_train_dataset = tf.constant(X_train, dtype=tf.float64)\n",
    "    tf_train_labels = tf.constant(y_train, dtype=tf.float64)\n",
    "    tf_test_dataset = tf.constant(X_test)\n",
    "\n",
    "    # Variables\n",
    "    weights_1 = tf.Variable(tf.truncated_normal([num_features, num_hidden]), dtype=tf.float32, name=\"layer1_weights\")\n",
    "    weights_1 = tf.cast(weights_1, tf.float64)\n",
    "    #weights = tf.Variable(tf.truncated_normal([num_features, 1]), name=\"weights\")\n",
    "    biases_1 = tf.Variable(tf.zeros([num_hidden]), dtype=tf.float32, name=\"layer1_biases\")\n",
    "    biases_1 = tf.cast(biases_1, tf.float64)\n",
    "    weights_2 = tf.Variable(tf.truncated_normal([num_hidden,1]), dtype=tf.float32, name=\"layer2_weights\")\n",
    "    weights_2 = tf.cast(weights_2, tf.float64)\n",
    "    #weights = tf.Variable(tf.truncated_normal([num_features, 1]), name=\"weights\")\n",
    "    biases_2 = tf.Variable(tf.zeros([1]), dtype=tf.float32, name=\"layer2_biases\")\n",
    "    biases_2 = tf.cast(biases_2, tf.float64)\n",
    "    steps = tf.Variable(0)\n",
    "    \n",
    "     # Model\n",
    "    def model(x, train=False):\n",
    "        hidden = tf.nn.relu(tf.matmul(x, weights_1) + biases_1)\n",
    "        return tf.matmul(hidden, weights_2) + biases_2\n",
    "    \n",
    "    # Loss Computation\n",
    "    train_prediction = model(tf_train_dataset)\n",
    "    loss = 0.5 * tf.reduce_mean(tf.squared_difference(tf_train_labels, train_prediction))\n",
    "    cost = tf.sqrt(loss)\n",
    "\n",
    "    # Optimizer\n",
    "    # Exponential decay of learning rate\n",
    "    learning_rate = tf.train.exponential_decay(0.06, steps, 5000, 0.70, staircase=True)\n",
    "    optimizer = tf.train.GradientDescentOptimizer(learning_rate).minimize(cost, global_step=steps)\n",
    "\n",
    "    # Predictions\n",
    "    test_prediction = model(tf_test_dataset)\n",
    "\n",
    "    saver = tf.train.Saver()\n",
    "\n",
    "num_steps = 100001\n",
    "\n",
    "def accuracy(prediction, labels):\n",
    "    return 0.5 * np.sqrt(((prediction - labels) ** 2).mean(axis=None))\n",
    "\n",
    "# Running graph\n",
    "with tf.Session(graph=graph) as sess:\n",
    "  tf.global_variables_initializer().run()\n",
    "  print('Initialized')\n",
    "  for step in range(num_steps):\n",
    "      # Run the computations. We tell .run() that we want to run the optimizer,\n",
    "      # and get the loss value and the training predictions returned as numpy\n",
    "      # arrays.\n",
    "      _, c, predictions = sess.run([optimizer, cost, train_prediction])\n",
    "      if (step % 5000 == 0):\n",
    "          print('Cost at step %d: %.2f' % (step, c))\n",
    "          # Calling .eval() on valid_prediction is basically like calling run(), but\n",
    "          # just to get that one numpy array. Note that it recomputes all its graph\n",
    "          # dependencies.\n",
    "          #print('Validation loss: %.2f' % accuracy(valid_prediction.eval(), y_valid))\n",
    "  t_pred = test_prediction.eval()\n",
    "  print('Test loss: %.2f' % accuracy(t_pred, y_test))\n",
    "  save_path = saver.save(sess, \"./model/nn-model.ckpt\")\n",
    "  print('Model saved in %s' % (save_path))\n",
    "  \n",
    "  print(\"r2 score: \", r2_score(y_test,t_pred))\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
